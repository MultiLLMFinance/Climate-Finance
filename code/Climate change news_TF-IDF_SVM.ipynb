{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "                                              0.0/294.9 kB ? eta -:--:--\n",
      "     -----------------------------          225.3/294.9 kB 6.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 294.9/294.9 kB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ----------\n",
      "absl-py                      1.4.0\n",
      "accelerate                   1.4.0.dev0\n",
      "aiohappyeyeballs             2.4.4\n",
      "aiohttp                      3.11.11\n",
      "aiosignal                    1.3.2\n",
      "asttokens                    3.0.0\n",
      "astunparse                   1.6.3\n",
      "attrs                        25.1.0\n",
      "baidu-aip                    4.16.13\n",
      "bitsandbytes                 0.45.1\n",
      "cachetools                   5.3.1\n",
      "certifi                      2023.7.22\n",
      "charset-normalizer           3.2.0\n",
      "click                        8.1.8\n",
      "colorama                     0.4.6\n",
      "comm                         0.2.2\n",
      "contourpy                    1.1.0\n",
      "cycler                       0.11.0\n",
      "datasets                     3.2.0\n",
      "debugpy                      1.8.12\n",
      "decorator                    5.1.1\n",
      "dill                         0.3.8\n",
      "et-xmlfile                   1.1.0\n",
      "executing                    2.2.0\n",
      "filelock                     3.12.4\n",
      "flatbuffers                  23.5.26\n",
      "fonttools                    4.42.1\n",
      "frozenlist                   1.5.0\n",
      "fsspec                       2023.9.2\n",
      "gast                         0.4.0\n",
      "google-auth                  2.22.0\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.57.0\n",
      "h5py                         3.9.0\n",
      "huggingface-hub              0.28.1\n",
      "idna                         3.4\n",
      "ipykernel                    6.29.5\n",
      "ipython                      8.32.0\n",
      "jedi                         0.19.2\n",
      "jieba                        0.42.1\n",
      "Jinja2                       3.1.2\n",
      "joblib                       1.3.2\n",
      "jupyter_client               8.6.3\n",
      "jupyter_core                 5.7.2\n",
      "keras                        2.13.1\n",
      "kiwisolver                   1.4.5\n",
      "libclang                     16.0.6\n",
      "lxml                         5.3.0\n",
      "Markdown                     3.4.4\n",
      "MarkupSafe                   2.1.3\n",
      "matplotlib                   3.7.2\n",
      "matplotlib-inline            0.1.7\n",
      "mpmath                       1.3.0\n",
      "multidict                    6.1.0\n",
      "multiprocess                 0.70.16\n",
      "nest-asyncio                 1.6.0\n",
      "networkx                     3.1\n",
      "nltk                         3.9.1\n",
      "numpy                        1.24.3\n",
      "oauthlib                     3.2.2\n",
      "openpyxl                     3.1.2\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.1\n",
      "pandas                       2.0.3\n",
      "parso                        0.8.4\n",
      "patsy                        0.5.3\n",
      "peft                         0.5.0\n",
      "Pillow                       10.0.0\n",
      "pip                          23.1.2\n",
      "platformdirs                 4.3.6\n",
      "prompt_toolkit               3.0.50\n",
      "propcache                    0.2.1\n",
      "protobuf                     4.24.1\n",
      "psutil                       6.1.1\n",
      "pure_eval                    0.2.3\n",
      "pyarrow                      19.0.0\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "Pygments                     2.19.1\n",
      "pyparsing                    3.0.9\n",
      "pysentiment2                 0.1.1\n",
      "python-dateutil              2.8.2\n",
      "python-docx                  1.1.2\n",
      "pytz                         2023.3\n",
      "pywin32                      308\n",
      "PyYAML                       6.0.1\n",
      "pyzmq                        26.2.1\n",
      "regex                        2023.10.3\n",
      "requests                     2.32.3\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.9\n",
      "safetensors                  0.5.2\n",
      "scikit-learn                 1.5.0\n",
      "scipy                        1.11.3\n",
      "seaborn                      0.13.2\n",
      "sentencepiece                0.2.0\n",
      "setuptools                   65.5.0\n",
      "six                          1.16.0\n",
      "stack-data                   0.6.3\n",
      "statsmodels                  0.14.0\n",
      "sympy                        1.12\n",
      "tensorboard                  2.13.0\n",
      "tensorboard-data-server      0.7.1\n",
      "tensorflow                   2.13.0\n",
      "tensorflow-estimator         2.13.0\n",
      "tensorflow-intel             2.13.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.3.0\n",
      "threadpoolctl                3.2.0\n",
      "tokenizers                   0.21.0\n",
      "torch                        2.1.0\n",
      "tornado                      6.4.2\n",
      "tqdm                         4.67.1\n",
      "traitlets                    5.14.3\n",
      "transformers                 4.48.2\n",
      "typing_extensions            4.12.2\n",
      "tzdata                       2023.3\n",
      "urllib3                      1.26.16\n",
      "wcwidth                      0.2.13\n",
      "Werkzeug                     2.3.7\n",
      "wheel                        0.41.2\n",
      "wrapt                        1.15.0\n",
      "xxhash                       3.5.0\n",
      "yarl                         1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0.0: 455, 1.0: 435}\n",
      "Class distribution for long-term prediction: {1.0: 463, 0.0: 427}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.5086\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5243\n",
      "Test AUC for Layer 2: 0.5534\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5556\n",
      "Test AUC for Layer 3: 0.5309\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5132\n",
      "Average Test AUC across all layers: 0.5310\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5328\n",
      "Test AUC for Layer 1: 0.6065\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5146\n",
      "Test AUC for Layer 2: 0.4958\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5417\n",
      "Test AUC for Layer 3: 0.5543\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5297\n",
      "Average Test AUC across all layers: 0.5522\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4660\n",
      "Test AUC for Layer 2: 0.4877\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5972\n",
      "Test AUC for Layer 3: 0.5726\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5077\n",
      "Average Test AUC across all layers: 0.5201\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3942\n",
      "Test AUC for Layer 1: 0.4662\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4854\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4306\n",
      "Test AUC for Layer 3: 0.5681\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4367\n",
      "Average Test AUC across all layers: 0.5114\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 476\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    475\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m ClimateNewsStockPredictor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 476\u001b[0m     \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefine_time_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 459\u001b[0m, in \u001b[0;36mClimateNewsStockPredictor.run_all_combinations\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combination, results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 459\u001b[0m     text_col, label_col \u001b[38;5;241m=\u001b[39m combination\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCombination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize the top features and learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # 1. Top Features\n",
    "        plt.subplot(1, 2, 1)\n",
    "        tfidf_vectorizer = layer_result['model'].named_steps['tfidf']\n",
    "        classifier = layer_result['model'].named_steps['classifier']\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get feature importances\n",
    "        coefs = classifier.coef_[0]\n",
    "        \n",
    "        # Get top positive and negative features\n",
    "        top_positive_idx = np.argsort(coefs)[-15:]\n",
    "        top_negative_idx = np.argsort(coefs)[:15]\n",
    "        \n",
    "        # Combine top features\n",
    "        top_idx = np.concatenate([top_negative_idx, top_positive_idx])\n",
    "        top_features = [feature_names[i] for i in top_idx]\n",
    "        top_coefs = coefs[top_idx]\n",
    "        \n",
    "        # Plot\n",
    "        plt.barh(range(len(top_features)), top_coefs)\n",
    "        plt.yticks(range(len(top_features)), top_features)\n",
    "        plt.title('Top Predictive Features')\n",
    "        plt.xlabel('Coefficient (Negative = Bearish, Positive = Bullish)')\n",
    "        \n",
    "        # 2. Learning Curve (using accuracy on different dataset sizes)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "            print(f\"Average Accuracy: {results.get('avg_accuracy', 'N/A'):.4f}\")\n",
    "            print(f\"Average AUC: {results.get('avg_auc', 'N/A'):.4f}\")\n",
    "            \n",
    "            # Print layer-specific results\n",
    "            for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                auc = results.get('auc', [])[i]\n",
    "                best_params = results.get('best_params', [])[i]\n",
    "                print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0.0: 455, 1.0: 435}\n",
      "Class distribution for long-term prediction: {1.0: 463, 0.0: 427}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4818\n",
      "Test AUC for Layer 1: 0.4976\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5437\n",
      "Test AUC for Layer 2: 0.5621\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5139\n",
      "Test AUC for Layer 3: 0.5341\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5131\n",
      "Average Test AUC across all layers: 0.5313\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5839\n",
      "Test AUC for Layer 1: 0.6524\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5146\n",
      "Test AUC for Layer 2: 0.5128\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4722\n",
      "Test AUC for Layer 3: 0.4925\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5236\n",
      "Average Test AUC across all layers: 0.5526\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4563\n",
      "Test AUC for Layer 2: 0.4950\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5694\n",
      "Test AUC for Layer 3: 0.6103\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4952\n",
      "Average Test AUC across all layers: 0.5351\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2701\n",
      "Test AUC for Layer 1: 0.5905\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4854\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4028\n",
      "Test AUC for Layer 3: 0.5893\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.3861\n",
      "Average Test AUC across all layers: 0.5599\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 485\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    484\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m ClimateNewsStockPredictor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 485\u001b[0m     \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefine_time_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 468\u001b[0m, in \u001b[0;36mClimateNewsStockPredictor.run_all_combinations\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combination, results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 468\u001b[0m     text_col, label_col \u001b[38;5;241m=\u001b[39m combination\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCombination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=1000,  # Limit to top 1000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize the top features and learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # 1. Top Features\n",
    "        plt.subplot(1, 2, 1)\n",
    "        tfidf_vectorizer = layer_result['model'].named_steps['tfidf']\n",
    "        classifier = layer_result['model'].named_steps['classifier']\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get feature importances\n",
    "        coefs = classifier.coef_[0]\n",
    "        \n",
    "        # Get top positive and negative features\n",
    "        top_positive_idx = np.argsort(coefs)[-15:]\n",
    "        top_negative_idx = np.argsort(coefs)[:15]\n",
    "        \n",
    "        # Combine top features\n",
    "        top_idx = np.concatenate([top_negative_idx, top_positive_idx])\n",
    "        top_features = [feature_names[i] for i in top_idx]\n",
    "        top_coefs = coefs[top_idx]\n",
    "        \n",
    "        # Plot\n",
    "        plt.barh(range(len(top_features)), top_coefs)\n",
    "        plt.yticks(range(len(top_features)), top_features)\n",
    "        plt.title('Top Predictive Features')\n",
    "        plt.xlabel('Coefficient (Negative = Bearish, Positive = Bullish)')\n",
    "        \n",
    "        # 2. Learning Curve (using accuracy on different dataset sizes)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "            print(f\"Average Accuracy: {results.get('avg_accuracy', 'N/A'):.4f}\")\n",
    "            print(f\"Average AUC: {results.get('avg_auc', 'N/A'):.4f}\")\n",
    "            \n",
    "            # Print layer-specific results\n",
    "            for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                auc = results.get('auc', [])[i]\n",
    "                best_params = results.get('best_params', [])[i]\n",
    "                print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0.0: 455, 1.0: 435}\n",
      "Class distribution for long-term prediction: {1.0: 463, 0.0: 427}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4818\n",
      "Test AUC for Layer 1: 0.4976\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5437\n",
      "Test AUC for Layer 2: 0.5621\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5139\n",
      "Test AUC for Layer 3: 0.5341\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5131\n",
      "Average Test AUC across all layers: 0.5313\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5839\n",
      "Test AUC for Layer 1: 0.6524\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5146\n",
      "Test AUC for Layer 2: 0.5128\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4722\n",
      "Test AUC for Layer 3: 0.4925\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5236\n",
      "Average Test AUC across all layers: 0.5526\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4660\n",
      "Test AUC for Layer 2: 0.5061\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5417\n",
      "Test AUC for Layer 3: 0.5277\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4892\n",
      "Average Test AUC across all layers: 0.5113\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3942\n",
      "Test AUC for Layer 1: 0.4749\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4854\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4306\n",
      "Test AUC for Layer 3: 0.5586\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4367\n",
      "Average Test AUC across all layers: 0.5112\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 485\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    484\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m ClimateNewsStockPredictor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 485\u001b[0m     \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefine_time_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 468\u001b[0m, in \u001b[0;36mClimateNewsStockPredictor.run_all_combinations\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combination, results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 468\u001b[0m     text_col, label_col \u001b[38;5;241m=\u001b[39m combination\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCombination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=10000,  # Limit to top 10000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize the top features and learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # 1. Top Features\n",
    "        plt.subplot(1, 2, 1)\n",
    "        tfidf_vectorizer = layer_result['model'].named_steps['tfidf']\n",
    "        classifier = layer_result['model'].named_steps['classifier']\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get feature importances\n",
    "        coefs = classifier.coef_[0]\n",
    "        \n",
    "        # Get top positive and negative features\n",
    "        top_positive_idx = np.argsort(coefs)[-15:]\n",
    "        top_negative_idx = np.argsort(coefs)[:15]\n",
    "        \n",
    "        # Combine top features\n",
    "        top_idx = np.concatenate([top_negative_idx, top_positive_idx])\n",
    "        top_features = [feature_names[i] for i in top_idx]\n",
    "        top_coefs = coefs[top_idx]\n",
    "        \n",
    "        # Plot\n",
    "        plt.barh(range(len(top_features)), top_coefs)\n",
    "        plt.yticks(range(len(top_features)), top_features)\n",
    "        plt.title('Top Predictive Features')\n",
    "        plt.xlabel('Coefficient (Negative = Bearish, Positive = Bullish)')\n",
    "        \n",
    "        # 2. Learning Curve (using accuracy on different dataset sizes)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "            print(f\"Average Accuracy: {results.get('avg_accuracy', 'N/A'):.4f}\")\n",
    "            print(f\"Average AUC: {results.get('avg_auc', 'N/A'):.4f}\")\n",
    "            \n",
    "            # Print layer-specific results\n",
    "            for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                auc = results.get('auc', [])[i]\n",
    "                best_params = results.get('best_params', [])[i]\n",
    "                print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1.0: 476, 0.0: 414}\n",
      "Class distribution for long-term prediction: {1.0: 489, 0.0: 401}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4745\n",
      "Test AUC for Layer 1: 0.5236\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4563\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4769\n",
      "Average Test AUC across all layers: 0.5079\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4307\n",
      "Test AUC for Layer 1: 0.5127\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4272\n",
      "Test AUC for Layer 2: 0.4569\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4444\n",
      "Test AUC for Layer 3: 0.5128\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4341\n",
      "Average Test AUC across all layers: 0.4941\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4964\n",
      "Test AUC for Layer 1: 0.4930\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5534\n",
      "Test AUC for Layer 2: 0.5874\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5166\n",
      "Average Test AUC across all layers: 0.5268\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.5362\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4369\n",
      "Test AUC for Layer 2: 0.4838\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5417\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4795\n",
      "Average Test AUC across all layers: 0.5067\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_CVX_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1.0: 485, 0.0: 405}\n",
      "Class distribution for long-term prediction: {1.0: 531, 0.0: 359}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4453\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5340\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5556\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5116\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.7080\n",
      "Test AUC for Layer 1: 0.6484\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5922\n",
      "Test AUC for Layer 2: 0.5759\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.3889\n",
      "Test AUC for Layer 3: 0.4075\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5631\n",
      "Average Test AUC across all layers: 0.5439\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4453\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5631\n",
      "Test AUC for Layer 2: 0.5409\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5833\n",
      "Test AUC for Layer 3: 0.5234\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5306\n",
      "Average Test AUC across all layers: 0.5214\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.6058\n",
      "Test AUC for Layer 1: 0.6345\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.6019\n",
      "Test AUC for Layer 2: 0.6378\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4028\n",
      "Test AUC for Layer 3: 0.4180\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5369\n",
      "Average Test AUC across all layers: 0.5634\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_MPC_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0.0: 462, 1.0: 428}\n",
      "Class distribution for long-term prediction: {0.0: 465, 1.0: 425}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4818\n",
      "Test AUC for Layer 1: 0.4982\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4951\n",
      "Test AUC for Layer 2: 0.4603\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5694\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5154\n",
      "Average Test AUC across all layers: 0.4862\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5109\n",
      "Test AUC for Layer 1: 0.5391\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5146\n",
      "Test AUC for Layer 2: 0.5403\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6667\n",
      "Test AUC for Layer 3: 0.4848\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5641\n",
      "Average Test AUC across all layers: 0.5214\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5328\n",
      "Test AUC for Layer 1: 0.5574\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4951\n",
      "Test AUC for Layer 2: 0.5308\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5694\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5325\n",
      "Average Test AUC across all layers: 0.5294\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.3650\n",
      "Test AUC for Layer 1: 0.5844\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5049\n",
      "Test AUC for Layer 2: 0.5784\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.6806\n",
      "Test AUC for Layer 3: 0.5773\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5168\n",
      "Average Test AUC across all layers: 0.5800\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_SLB_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 890 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1.0: 451, 0.0: 439}\n",
      "Class distribution for long-term prediction: {1.0: 449, 0.0: 441}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4672\n",
      "Test AUC for Layer 1: 0.4873\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4466\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4306\n",
      "Test AUC for Layer 3: 0.5323\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4481\n",
      "Average Test AUC across all layers: 0.5065\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5620\n",
      "Test AUC for Layer 1: 0.6219\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5825\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5139\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5528\n",
      "Average Test AUC across all layers: 0.5406\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4891\n",
      "Test AUC for Layer 1: 0.4565\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4854\n",
      "Test AUC for Layer 2: 0.5252\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4861\n",
      "Test AUC for Layer 3: 0.4697\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4869\n",
      "Average Test AUC across all layers: 0.4838\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.3796\n",
      "Test AUC for Layer 1: 0.6086\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5825\n",
      "Test AUC for Layer 2: 0.4190\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 72 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.5328\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4874\n",
      "Average Test AUC across all layers: 0.5202\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_XOM_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 889 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0.0: 455, 1.0: 434}\n",
      "Class distribution for long-term prediction: {1.0: 463, 0.0: 426}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5146\n",
      "Test AUC for Layer 2: 0.4989\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6056\n",
      "Test AUC for Layer 3: 0.6620\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5267\n",
      "Average Test AUC across all layers: 0.5536\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.6131\n",
      "Test AUC for Layer 1: 0.6657\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4369\n",
      "Test AUC for Layer 2: 0.4642\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5352\n",
      "Test AUC for Layer 3: 0.5621\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5284\n",
      "Average Test AUC across all layers: 0.5640\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4599\n",
      "Test AUC for Layer 1: 0.4910\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4369\n",
      "Test AUC for Layer 2: 0.5046\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6056\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5008\n",
      "Average Test AUC across all layers: 0.4985\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4672\n",
      "Test AUC for Layer 1: 0.5803\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4175\n",
      "Test AUC for Layer 2: 0.3989\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5634\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4827\n",
      "Average Test AUC across all layers: 0.4930\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 889 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1.0: 476, 0.0: 413}\n",
      "Class distribution for long-term prediction: {1.0: 489, 0.0: 400}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5839\n",
      "Test AUC for Layer 1: 0.5615\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5437\n",
      "Test AUC for Layer 2: 0.4554\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4930\n",
      "Test AUC for Layer 3: 0.4401\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5402\n",
      "Average Test AUC across all layers: 0.4857\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4672\n",
      "Test AUC for Layer 1: 0.5676\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4563\n",
      "Test AUC for Layer 2: 0.4611\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5493\n",
      "Test AUC for Layer 3: 0.4840\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4909\n",
      "Average Test AUC across all layers: 0.5042\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5328\n",
      "Test AUC for Layer 1: 0.5301\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5049\n",
      "Test AUC for Layer 2: 0.4833\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5211\n",
      "Test AUC for Layer 3: 0.5992\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5196\n",
      "Average Test AUC across all layers: 0.5375\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4672\n",
      "Test AUC for Layer 1: 0.5711\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5243\n",
      "Test AUC for Layer 2: 0.5069\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5493\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5136\n",
      "Average Test AUC across all layers: 0.5260\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_CVX_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 889 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1.0: 485, 0.0: 404}\n",
      "Class distribution for long-term prediction: {1.0: 531, 0.0: 358}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4453\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5825\n",
      "Test AUC for Layer 2: 0.6244\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5634\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5304\n",
      "Average Test AUC across all layers: 0.5415\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5474\n",
      "Test AUC for Layer 1: 0.5608\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4369\n",
      "Test AUC for Layer 2: 0.4435\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4789\n",
      "Test AUC for Layer 3: 0.3716\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4877\n",
      "Average Test AUC across all layers: 0.4586\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4453\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4854\n",
      "Test AUC for Layer 2: 0.5129\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5493\n",
      "Test AUC for Layer 3: 0.6089\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4933\n",
      "Average Test AUC across all layers: 0.5406\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5620\n",
      "Test AUC for Layer 1: 0.5657\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5825\n",
      "Test AUC for Layer 2: 0.5593\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4507\n",
      "Test AUC for Layer 3: 0.4396\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5318\n",
      "Average Test AUC across all layers: 0.5215\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_MPC_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 889 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0.0: 461, 1.0: 428}\n",
      "Class distribution for long-term prediction: {0.0: 464, 1.0: 425}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5036\n",
      "Test AUC for Layer 1: 0.4811\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4272\n",
      "Test AUC for Layer 2: 0.4730\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5634\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4981\n",
      "Average Test AUC across all layers: 0.4847\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4964\n",
      "Test AUC for Layer 1: 0.4947\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4951\n",
      "Test AUC for Layer 2: 0.4906\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6620\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5512\n",
      "Average Test AUC across all layers: 0.4951\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4818\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4272\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5634\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4908\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5255\n",
      "Test AUC for Layer 1: 0.5625\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5825\n",
      "Test AUC for Layer 2: 0.5950\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.7324\n",
      "Test AUC for Layer 3: 0.6348\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.6135\n",
      "Average Test AUC across all layers: 0.5974\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_SLB_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 889 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1.0: 451, 0.0: 438}\n",
      "Class distribution for long-term prediction: {1.0: 449, 0.0: 440}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5255\n",
      "Test AUC for Layer 1: 0.5518\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4466\n",
      "Test AUC for Layer 2: 0.4737\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4366\n",
      "Test AUC for Layer 3: 0.5323\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4696\n",
      "Average Test AUC across all layers: 0.5193\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2701\n",
      "Test AUC for Layer 1: 0.5978\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4466\n",
      "Test AUC for Layer 2: 0.4452\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5070\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4079\n",
      "Average Test AUC across all layers: 0.5143\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4526\n",
      "Test AUC for Layer 1: 0.4097\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4563\n",
      "Test AUC for Layer 2: 0.5057\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4648\n",
      "Test AUC for Layer 3: 0.5024\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4579\n",
      "Average Test AUC across all layers: 0.4726\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 437 samples\n",
      "Validation data: 139 samples\n",
      "Test data: 137 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2701\n",
      "Test AUC for Layer 1: 0.5565\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 576 samples\n",
      "Validation data: 137 samples\n",
      "Test data: 103 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4369\n",
      "Test AUC for Layer 2: 0.4194\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 714 samples\n",
      "Validation data: 103 samples\n",
      "Test data: 71 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4930\n",
      "Test AUC for Layer 3: 0.5008\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4000\n",
      "Average Test AUC across all layers: 0.4922\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_XOM_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0: 431, 1: 407}\n",
      "Class distribution for long-term prediction: {1: 440, 0: 398}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5038\n",
      "Test AUC for Layer 1: 0.5116\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4455\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5857\n",
      "Test AUC for Layer 3: 0.5765\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5117\n",
      "Average Test AUC across all layers: 0.5294\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5865\n",
      "Test AUC for Layer 1: 0.6455\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4158\n",
      "Test AUC for Layer 2: 0.4359\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5143\n",
      "Test AUC for Layer 3: 0.4996\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5055\n",
      "Average Test AUC across all layers: 0.5270\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4662\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4455\n",
      "Test AUC for Layer 2: 0.5377\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6000\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5039\n",
      "Average Test AUC across all layers: 0.5126\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2632\n",
      "Test AUC for Layer 1: 0.5534\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4950\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5286\n",
      "Test AUC for Layer 3: 0.5815\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4289\n",
      "Average Test AUC across all layers: 0.5449\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 452, 0: 386}\n",
      "Class distribution for long-term prediction: {1: 464, 0: 374}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3910\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4857\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4473\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5414\n",
      "Test AUC for Layer 1: 0.5345\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4158\n",
      "Test AUC for Layer 2: 0.4919\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5048\n",
      "Average Test AUC across all layers: 0.5088\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3910\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.4961\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5143\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4569\n",
      "Average Test AUC across all layers: 0.4987\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2632\n",
      "Test AUC for Layer 1: 0.5472\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.4625\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4285\n",
      "Average Test AUC across all layers: 0.5032\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_CVX_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 460, 0: 378}\n",
      "Class distribution for long-term prediction: {1: 503, 0: 335}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4511\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.5272\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5857\n",
      "Test AUC for Layer 3: 0.5550\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5007\n",
      "Average Test AUC across all layers: 0.5274\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.7218\n",
      "Test AUC for Layer 1: 0.5751\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.6040\n",
      "Test AUC for Layer 2: 0.5804\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4714\n",
      "Test AUC for Layer 3: 0.3856\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5991\n",
      "Average Test AUC across all layers: 0.5137\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5338\n",
      "Test AUC for Layer 1: 0.5128\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5446\n",
      "Test AUC for Layer 2: 0.5307\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5714\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5499\n",
      "Average Test AUC across all layers: 0.5145\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.6241\n",
      "Test AUC for Layer 1: 0.6434\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.6535\n",
      "Test AUC for Layer 2: 0.5939\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4286\n",
      "Test AUC for Layer 3: 0.4461\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5687\n",
      "Average Test AUC across all layers: 0.5611\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_MPC_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0: 433, 1: 405}\n",
      "Class distribution for long-term prediction: {0: 437, 1: 401}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4887\n",
      "Test AUC for Layer 1: 0.4893\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4257\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4905\n",
      "Average Test AUC across all layers: 0.4964\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5188\n",
      "Test AUC for Layer 1: 0.5594\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5149\n",
      "Test AUC for Layer 2: 0.5481\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5636\n",
      "Average Test AUC across all layers: 0.5358\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4887\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4851\n",
      "Test AUC for Layer 2: 0.5020\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5103\n",
      "Average Test AUC across all layers: 0.5007\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.3684\n",
      "Test AUC for Layer 1: 0.6018\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5644\n",
      "Test AUC for Layer 2: 0.5730\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.6429\n",
      "Test AUC for Layer 3: 0.6232\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5252\n",
      "Average Test AUC across all layers: 0.5993\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_SLB_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 427, 0: 411}\n",
      "Class distribution for long-term prediction: {1: 428, 0: 410}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4436\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4554\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4854\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4662\n",
      "Test AUC for Layer 1: 0.6312\n",
      "Visualization saved as: visualization_Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5842\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.4849\n",
      "Visualization saved as: visualization_Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5168\n",
      "Average Test AUC across all layers: 0.5387\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4511\n",
      "Test AUC for Layer 1: 0.4137\n",
      "Visualization saved as: visualization_Full text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5347\n",
      "Test AUC for Layer 2: 0.5514\n",
      "Visualization saved as: visualization_Full text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Full text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5143\n",
      "Average Test AUC across all layers: 0.4883\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2707\n",
      "Test AUC for Layer 1: 0.5839\n",
      "Visualization saved as: visualization_Full text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5149\n",
      "Test AUC for Layer 2: 0.5424\n",
      "Visualization saved as: visualization_Full text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.5127\n",
      "Visualization saved as: visualization_Full text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4285\n",
      "Average Test AUC across all layers: 0.5463\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_XOM_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0: 431, 1: 407}\n",
      "Class distribution for long-term prediction: {1: 440, 0: 398}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4962\n",
      "Test AUC for Layer 1: 0.5143\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4455\n",
      "Test AUC for Layer 2: 0.5317\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5143\n",
      "Test AUC for Layer 3: 0.4872\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4854\n",
      "Average Test AUC across all layers: 0.5111\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2632\n",
      "Test AUC for Layer 1: 0.5589\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4950\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5286\n",
      "Test AUC for Layer 3: 0.5815\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4289\n",
      "Average Test AUC across all layers: 0.5468\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_title_full_text_SP500_database/semantic/wall_street_news_semantics_COP_completed_Merged.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 452, 0: 386}\n",
      "Class distribution for long-term prediction: {1: 464, 0: 374}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5564\n",
      "Test AUC for Layer 1: 0.4919\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5050\n",
      "Test AUC for Layer 2: 0.4590\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5143\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5252\n",
      "Average Test AUC across all layers: 0.4837\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2632\n",
      "Test AUC for Layer 1: 0.5397\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4356\n",
      "Test AUC for Layer 2: 0.4524\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4186\n",
      "Average Test AUC across all layers: 0.4973\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_title_full_text_SP500_database/semantic/wall_street_news_semantics_CVX_completed_Merged.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 460, 0: 378}\n",
      "Class distribution for long-term prediction: {1: 503, 0: 335}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4511\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4950\n",
      "Test AUC for Layer 2: 0.5126\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6286\n",
      "Test AUC for Layer 3: 0.5883\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5249\n",
      "Average Test AUC across all layers: 0.5336\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5038\n",
      "Test AUC for Layer 1: 0.5047\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5842\n",
      "Test AUC for Layer 2: 0.5906\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4143\n",
      "Test AUC for Layer 3: 0.4412\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5007\n",
      "Average Test AUC across all layers: 0.5121\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_title_full_text_SP500_database/semantic/wall_street_news_semantics_MPC_completed_Merged.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0: 433, 1: 405}\n",
      "Class distribution for long-term prediction: {0: 437, 1: 401}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5564\n",
      "Test AUC for Layer 1: 0.5776\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5545\n",
      "Test AUC for Layer 2: 0.5593\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5286\n",
      "Test AUC for Layer 3: 0.5095\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5465\n",
      "Average Test AUC across all layers: 0.5488\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.3684\n",
      "Test AUC for Layer 1: 0.6064\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5545\n",
      "Test AUC for Layer 2: 0.5420\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.6286\n",
      "Test AUC for Layer 3: 0.6286\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5171\n",
      "Average Test AUC across all layers: 0.5923\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_title_full_text_SP500_database/semantic/wall_street_news_semantics_SLB_completed_Merged.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 427, 0: 411}\n",
      "Class distribution for long-term prediction: {1: 428, 0: 410}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4511\n",
      "Test AUC for Layer 1: 0.4118\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4554\n",
      "Test AUC for Layer 2: 0.4601\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4879\n",
      "Average Test AUC across all layers: 0.4573\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.3910\n",
      "Test AUC for Layer 1: 0.6163\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5248\n",
      "Test AUC for Layer 2: 0.5254\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.5167\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4719\n",
      "Average Test AUC across all layers: 0.5528\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_title_full_text_SP500_database/semantic/wall_street_news_semantics_XOM_completed_Merged.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0: 431, 1: 407}\n",
      "Class distribution for long-term prediction: {1: 440, 0: 398}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5038\n",
      "Test AUC for Layer 1: 0.5116\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4455\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5857\n",
      "Test AUC for Layer 3: 0.5765\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5117\n",
      "Average Test AUC across all layers: 0.5294\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5865\n",
      "Test AUC for Layer 1: 0.6455\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4158\n",
      "Test AUC for Layer 2: 0.4359\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5143\n",
      "Test AUC for Layer 3: 0.4996\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5055\n",
      "Average Test AUC across all layers: 0.5270\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4662\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4455\n",
      "Test AUC for Layer 2: 0.5317\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6000\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5039\n",
      "Average Test AUC across all layers: 0.5106\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2632\n",
      "Test AUC for Layer 1: 0.5490\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4950\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5429\n",
      "Test AUC for Layer 3: 0.5823\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4337\n",
      "Average Test AUC across all layers: 0.5438\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (COP)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 573\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    572\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m ClimateNewsStockPredictor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 573\u001b[0m     \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefine_time_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all_combinations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 543\u001b[0m, in \u001b[0;36mClimateNewsStockPredictor.run_all_combinations\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# Create comprehensive summary table\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combination, results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 543\u001b[0m     text_col, label_col \u001b[38;5;241m=\u001b[39m combination\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCombination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/COP/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/COP/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/COP/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/COP/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (COP)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 452, 0: 386}\n",
      "Class distribution for long-term prediction: {1: 464, 0: 374}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3910\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4857\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4473\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5414\n",
      "Test AUC for Layer 1: 0.5345\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4158\n",
      "Test AUC for Layer 2: 0.4919\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5048\n",
      "Average Test AUC across all layers: 0.5088\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3910\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.4941\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5143\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4569\n",
      "Average Test AUC across all layers: 0.4980\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2632\n",
      "Test AUC for Layer 1: 0.5429\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4257\n",
      "Test AUC for Layer 2: 0.4592\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4153\n",
      "Average Test AUC across all layers: 0.5007\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (CVX)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4473\n",
      "Average AUC: 0.5000\n",
      "  Layer 1 - Accuracy: 0.3910, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4653, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4857, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.5048\n",
      "Average AUC: 0.5088\n",
      "  Layer 1 - Accuracy: 0.5414, AUC: 0.5345\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4158, AUC: 0.4919\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.4569\n",
      "Average AUC: 0.4980\n",
      "  Layer 1 - Accuracy: 0.3910, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4653, AUC: 0.4941\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5143, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.4153\n",
      "Average AUC: 0.5007\n",
      "  Layer 1 - Accuracy: 0.2632, AUC: 0.5429\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4257, AUC: 0.4592\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/CVX/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/CVX/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/CVX/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/CVX/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (CVX)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_CVX_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 460, 0: 378}\n",
      "Class distribution for long-term prediction: {1: 503, 0: 335}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4511\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4653\n",
      "Test AUC for Layer 2: 0.5272\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5857\n",
      "Test AUC for Layer 3: 0.5550\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5007\n",
      "Average Test AUC across all layers: 0.5274\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.7218\n",
      "Test AUC for Layer 1: 0.5751\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.6040\n",
      "Test AUC for Layer 2: 0.5804\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4714\n",
      "Test AUC for Layer 3: 0.3856\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5991\n",
      "Average Test AUC across all layers: 0.5137\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5113\n",
      "Test AUC for Layer 1: 0.4829\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5644\n",
      "Test AUC for Layer 2: 0.5504\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5714\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5490\n",
      "Average Test AUC across all layers: 0.5111\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5414\n",
      "Test AUC for Layer 1: 0.5300\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.5743\n",
      "Test AUC for Layer 2: 0.5922\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4429\n",
      "Test AUC for Layer 3: 0.4453\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5195\n",
      "Average Test AUC across all layers: 0.5225\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (MPC)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.5007\n",
      "Average AUC: 0.5274\n",
      "  Layer 1 - Accuracy: 0.4511, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4653, AUC: 0.5272\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5857, AUC: 0.5550\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.5991\n",
      "Average AUC: 0.5137\n",
      "  Layer 1 - Accuracy: 0.7218, AUC: 0.5751\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.6040, AUC: 0.5804\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4714, AUC: 0.3856\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.5490\n",
      "Average AUC: 0.5111\n",
      "  Layer 1 - Accuracy: 0.5113, AUC: 0.4829\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5644, AUC: 0.5504\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5714, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.5195\n",
      "Average AUC: 0.5225\n",
      "  Layer 1 - Accuracy: 0.5414, AUC: 0.5300\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5743, AUC: 0.5922\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4429, AUC: 0.4453\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/MPC/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/MPC/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/MPC/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/MPC/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (MPC)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_MPC_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {0: 433, 1: 405}\n",
      "Class distribution for long-term prediction: {0: 437, 1: 401}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4887\n",
      "Test AUC for Layer 1: 0.4893\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4257\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4905\n",
      "Average Test AUC across all layers: 0.4964\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5188\n",
      "Test AUC for Layer 1: 0.5594\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5149\n",
      "Test AUC for Layer 2: 0.5481\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.6571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5636\n",
      "Average Test AUC across all layers: 0.5358\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5564\n",
      "Test AUC for Layer 1: 0.5869\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5248\n",
      "Test AUC for Layer 2: 0.5766\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5461\n",
      "Average Test AUC across all layers: 0.5545\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.3684\n",
      "Test AUC for Layer 1: 0.5948\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5446\n",
      "Test AUC for Layer 2: 0.5546\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.6286\n",
      "Test AUC for Layer 3: 0.6322\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5138\n",
      "Average Test AUC across all layers: 0.5939\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (SLB)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4905\n",
      "Average AUC: 0.4964\n",
      "  Layer 1 - Accuracy: 0.4887, AUC: 0.4893\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4257, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.5636\n",
      "Average AUC: 0.5358\n",
      "  Layer 1 - Accuracy: 0.5188, AUC: 0.5594\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5149, AUC: 0.5481\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.6571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.5461\n",
      "Average AUC: 0.5545\n",
      "  Layer 1 - Accuracy: 0.5564, AUC: 0.5869\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5248, AUC: 0.5766\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.5138\n",
      "Average AUC: 0.5939\n",
      "  Layer 1 - Accuracy: 0.3684, AUC: 0.5948\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5446, AUC: 0.5546\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.6286, AUC: 0.6322\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/SLB/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/SLB/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/SLB/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/SLB/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (SLB)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_SLB_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 838 climate change news articles from Wall Street Journal spanning from 07/11/2014 to 24/09/2024\n",
      "Class distribution for short-term prediction: {1: 427, 0: 411}\n",
      "Class distribution for long-term prediction: {1: 428, 0: 410}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4436\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4554\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4854\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4662\n",
      "Test AUC for Layer 1: 0.6312\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5842\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.4849\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5168\n",
      "Average Test AUC across all layers: 0.5387\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4962\n",
      "Test AUC for Layer 1: 0.4217\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5248\n",
      "Test AUC for Layer 2: 0.5530\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5571\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5260\n",
      "Average Test AUC across all layers: 0.4915\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/11/2014 - 31/10/2020\n",
      "Validation period: 01/11/2020 - 31/10/2021\n",
      "Testing period: 01/11/2021 - 31/10/2022\n",
      "Training data: 401 samples\n",
      "Validation data: 131 samples\n",
      "Test data: 133 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.2707\n",
      "Test AUC for Layer 1: 0.5828\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/11/2014 - 31/10/2021\n",
      "Validation period: 01/11/2021 - 31/10/2022\n",
      "Testing period: 01/11/2022 - 31/10/2023\n",
      "Training data: 532 samples\n",
      "Validation data: 133 samples\n",
      "Test data: 101 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4158\n",
      "Test AUC for Layer 2: 0.4213\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/11/2014 - 31/10/2022\n",
      "Validation period: 01/11/2022 - 31/10/2023\n",
      "Testing period: 01/11/2023 - 01/11/2024\n",
      "Training data: 666 samples\n",
      "Validation data: 101 samples\n",
      "Test data: 70 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5000\n",
      "Test AUC for Layer 3: 0.5143\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.3955\n",
      "Average Test AUC across all layers: 0.5061\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (XOM)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4854\n",
      "Average AUC: 0.5000\n",
      "  Layer 1 - Accuracy: 0.4436, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4554, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.5168\n",
      "Average AUC: 0.5387\n",
      "  Layer 1 - Accuracy: 0.4662, AUC: 0.6312\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5842, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5000, AUC: 0.4849\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.5260\n",
      "Average AUC: 0.4915\n",
      "  Layer 1 - Accuracy: 0.4962, AUC: 0.4217\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5248, AUC: 0.5530\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5571, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.3955\n",
      "Average AUC: 0.5061\n",
      "  Layer 1 - Accuracy: 0.2707, AUC: 0.5828\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4158, AUC: 0.4213\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5000, AUC: 0.5143\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/XOM/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/XOM/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/XOM/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2014-2020), validation (2020-2021), test (2021-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2020-10-31'),\n",
    "            'val_start': pd.Timestamp('2020-11-01'),\n",
    "            'val_end': pd.Timestamp('2021-10-31'),\n",
    "            'test_start': pd.Timestamp('2021-11-01'),\n",
    "            'test_end': pd.Timestamp('2022-10-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2014-2021), validation (2021-2022), test (2022-2023)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2021-10-31'),\n",
    "            'val_start': pd.Timestamp('2021-11-01'),\n",
    "            'val_end': pd.Timestamp('2022-10-31'),\n",
    "            'test_start': pd.Timestamp('2022-11-01'),\n",
    "            'test_end': pd.Timestamp('2023-10-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2014-2022), validation (2022-2023), test (2023-2024)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2014-11-01'),\n",
    "            'train_end': pd.Timestamp('2022-10-31'),\n",
    "            'val_start': pd.Timestamp('2022-11-01'),\n",
    "            'val_end': pd.Timestamp('2023-10-31'),\n",
    "            'test_start': pd.Timestamp('2023-11-01'),\n",
    "            'test_end': pd.Timestamp('2024-11-01')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/XOM/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (XOM)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/wall_street_news_semantics_SP500_database/wall_street_news_semantics_XOM_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {0: 469, 1: 460}\n",
      "Class distribution for long-term prediction: {1: 504, 0: 425}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4697\n",
      "Test AUC for Layer 1: 0.4773\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4722\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5507\n",
      "Test AUC for Layer 3: 0.4873\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4975\n",
      "Average Test AUC across all layers: 0.4882\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.2424\n",
      "Test AUC for Layer 1: 0.5364\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4630\n",
      "Test AUC for Layer 2: 0.4602\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4348\n",
      "Test AUC for Layer 3: 0.5427\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.3801\n",
      "Average Test AUC across all layers: 0.5131\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4545\n",
      "Test AUC for Layer 1: 0.4694\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4537\n",
      "Test AUC for Layer 2: 0.4183\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4493\n",
      "Test AUC for Layer 3: 0.4839\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4525\n",
      "Average Test AUC across all layers: 0.4572\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5000\n",
      "Test AUC for Layer 1: 0.6066\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.3519\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4348\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4289\n",
      "Average Test AUC across all layers: 0.5355\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (COP)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4975\n",
      "Average AUC: 0.4882\n",
      "  Layer 1 - Accuracy: 0.4697, AUC: 0.4773\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4722, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5507, AUC: 0.4873\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.3801\n",
      "Average AUC: 0.5131\n",
      "  Layer 1 - Accuracy: 0.2424, AUC: 0.5364\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4630, AUC: 0.4602\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4348, AUC: 0.5427\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.4525\n",
      "Average AUC: 0.4572\n",
      "  Layer 1 - Accuracy: 0.4545, AUC: 0.4694\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4537, AUC: 0.4183\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4493, AUC: 0.4839\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.4289\n",
      "Average AUC: 0.5355\n",
      "  Layer 1 - Accuracy: 0.5000, AUC: 0.6066\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.3519, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4348, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/COP/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/COP/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/COP/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/COP/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/COP/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/COP/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/COP/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (COP)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {0: 469, 1: 460}\n",
      "Class distribution for long-term prediction: {1: 504, 0: 425}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4545\n",
      "Test AUC for Layer 1: 0.4750\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4352\n",
      "Test AUC for Layer 2: 0.4307\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4928\n",
      "Test AUC for Layer 3: 0.4720\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4608\n",
      "Average Test AUC across all layers: 0.4592\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4848\n",
      "Test AUC for Layer 1: 0.6165\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4630\n",
      "Test AUC for Layer 2: 0.4647\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4348\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4609\n",
      "Average Test AUC across all layers: 0.5271\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (COP)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (COP)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_COP_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {1: 499, 0: 430}\n",
      "Class distribution for long-term prediction: {1: 521, 0: 408}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4545\n",
      "Test AUC for Layer 1: 0.4676\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.3981\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4638\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4388\n",
      "Average Test AUC across all layers: 0.4892\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5455\n",
      "Test AUC for Layer 1: 0.5694\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5463\n",
      "Test AUC for Layer 2: 0.5064\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.2754\n",
      "Test AUC for Layer 3: 0.5821\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4557\n",
      "Average Test AUC across all layers: 0.5526\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5152\n",
      "Test AUC for Layer 1: 0.4702\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4537\n",
      "Test AUC for Layer 2: 0.3360\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5362\n",
      "Test AUC for Layer 3: 0.5878\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5017\n",
      "Average Test AUC across all layers: 0.4647\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.2121\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.6296\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.2754\n",
      "Test AUC for Layer 3: 0.4653\n",
      "Visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.3724\n",
      "Average Test AUC across all layers: 0.4884\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (CVX)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4388\n",
      "Average AUC: 0.4892\n",
      "  Layer 1 - Accuracy: 0.4545, AUC: 0.4676\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.3981, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4638, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.4557\n",
      "Average AUC: 0.5526\n",
      "  Layer 1 - Accuracy: 0.5455, AUC: 0.5694\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5463, AUC: 0.5064\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.2754, AUC: 0.5821\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.5017\n",
      "Average AUC: 0.4647\n",
      "  Layer 1 - Accuracy: 0.5152, AUC: 0.4702\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4537, AUC: 0.3360\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5362, AUC: 0.5878\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.3724\n",
      "Average AUC: 0.4884\n",
      "  Layer 1 - Accuracy: 0.2121, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.6296, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.2754, AUC: 0.4653\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/CVX/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/CVX/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/CVX/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/CVX/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/CVX/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/CVX/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (CVX)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_CVX_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {1: 499, 0: 430}\n",
      "Class distribution for long-term prediction: {1: 521, 0: 408}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.5000\n",
      "Test AUC for Layer 1: 0.4681\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4722\n",
      "Test AUC for Layer 2: 0.3560\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.5652\n",
      "Test AUC for Layer 3: 0.5878\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5125\n",
      "Average Test AUC across all layers: 0.4707\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.2121\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.6296\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.2754\n",
      "Test AUC for Layer 3: 0.4611\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.3724\n",
      "Average Test AUC across all layers: 0.4870\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (CVX)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"F:/Python/my jupyter notebook/Merged_TF-IDF_SVM_Plots/CVX/visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (CVX)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_CVX_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {1: 482, 0: 447}\n",
      "Class distribution for long-term prediction: {1: 555, 0: 374}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3939\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4167\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4928\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4345\n",
      "Average Test AUC across all layers: 0.5000\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4697\n",
      "Test AUC for Layer 1: 0.4310\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4537\n",
      "Test AUC for Layer 2: 0.4319\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4783\n",
      "Test AUC for Layer 3: 0.4874\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4672\n",
      "Average Test AUC across all layers: 0.4501\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5455\n",
      "Test AUC for Layer 1: 0.5058\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4074\n",
      "Test AUC for Layer 2: 0.4123\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4638\n",
      "Test AUC for Layer 3: 0.4462\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4722\n",
      "Average Test AUC across all layers: 0.4548\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5606\n",
      "Test AUC for Layer 1: 0.3947\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.7315\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5217\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.6046\n",
      "Average Test AUC across all layers: 0.4649\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (MPC)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4345\n",
      "Average AUC: 0.5000\n",
      "  Layer 1 - Accuracy: 0.3939, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4167, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4928, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.4672\n",
      "Average AUC: 0.4501\n",
      "  Layer 1 - Accuracy: 0.4697, AUC: 0.4310\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4537, AUC: 0.4319\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4783, AUC: 0.4874\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.4722\n",
      "Average AUC: 0.4548\n",
      "  Layer 1 - Accuracy: 0.5455, AUC: 0.5058\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4074, AUC: 0.4123\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4638, AUC: 0.4462\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.6046\n",
      "Average AUC: 0.4649\n",
      "  Layer 1 - Accuracy: 0.5606, AUC: 0.3947\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.7315, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5217, AUC: 0.5000\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/MPC/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/MPC/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/MPC/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/MPC/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/MPC/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/MPC/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (MPC)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_MPC_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {1: 482, 0: 447}\n",
      "Class distribution for long-term prediction: {1: 555, 0: 374}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5303\n",
      "Test AUC for Layer 1: 0.5587\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4537\n",
      "Test AUC for Layer 2: 0.4310\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4638\n",
      "Test AUC for Layer 3: 0.4647\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4826\n",
      "Average Test AUC across all layers: 0.4848\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5000\n",
      "Test AUC for Layer 1: 0.4092\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.7315\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5217\n",
      "Test AUC for Layer 3: 0.5000\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5844\n",
      "Average Test AUC across all layers: 0.4697\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (CVX)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"F:/Python/my jupyter notebook/Merged_TF-IDF_SVM_Plots/MPC/visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (MPC)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_MPC_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {1: 472, 0: 457}\n",
      "Class distribution for long-term prediction: {1: 494, 0: 435}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4848\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4815\n",
      "Test AUC for Layer 2: 0.4518\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4493\n",
      "Test AUC for Layer 3: 0.4573\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4719\n",
      "Average Test AUC across all layers: 0.4697\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4848\n",
      "Test AUC for Layer 1: 0.4818\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.3333\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4638\n",
      "Test AUC for Layer 3: 0.5334\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4273\n",
      "Average Test AUC across all layers: 0.5051\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.4242\n",
      "Test AUC for Layer 1: 0.4044\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4444\n",
      "Test AUC for Layer 2: 0.4681\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4638\n",
      "Test AUC for Layer 3: 0.4966\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4442\n",
      "Average Test AUC across all layers: 0.4564\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.3485\n",
      "Test AUC for Layer 1: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5093\n",
      "Test AUC for Layer 2: 0.5397\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5362\n",
      "Test AUC for Layer 3: 0.5474\n",
      "Visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4647\n",
      "Average Test AUC across all layers: 0.5290\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (SLB)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4719\n",
      "Average AUC: 0.4697\n",
      "  Layer 1 - Accuracy: 0.4848, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4815, AUC: 0.4518\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4493, AUC: 0.4573\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.4273\n",
      "Average AUC: 0.5051\n",
      "  Layer 1 - Accuracy: 0.4848, AUC: 0.4818\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.3333, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4638, AUC: 0.5334\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.4442\n",
      "Average AUC: 0.4564\n",
      "  Layer 1 - Accuracy: 0.4242, AUC: 0.4044\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4444, AUC: 0.4681\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4638, AUC: 0.4966\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.4647\n",
      "Average AUC: 0.5290\n",
      "  Layer 1 - Accuracy: 0.3485, AUC: 0.5000\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.5093, AUC: 0.5397\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5362, AUC: 0.5474\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/SLB/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/SLB/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/SLB/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/SLB/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/SLB/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/SLB/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (SLB)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_SLB_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {1: 472, 0: 457}\n",
      "Class distribution for long-term prediction: {1: 494, 0: 435}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5455\n",
      "Test AUC for Layer 1: 0.6094\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4259\n",
      "Test AUC for Layer 2: 0.3881\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5362\n",
      "Test AUC for Layer 3: 0.5607\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5025\n",
      "Average Test AUC across all layers: 0.5194\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.6667\n",
      "Test AUC for Layer 1: 0.6795\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.5278\n",
      "Test AUC for Layer 2: 0.5289\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.3913\n",
      "Test AUC for Layer 3: 0.3907\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5286\n",
      "Average Test AUC across all layers: 0.5330\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (CVX)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"F:/Python/my jupyter notebook/Merged_TF-IDF_SVM_Plots/SLB/visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (SLB)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_SLB_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {0: 466, 1: 463}\n",
      "Class distribution for long-term prediction: {1: 507, 0: 422}\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4697\n",
      "Test AUC for Layer 1: 0.5215\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4352\n",
      "Test AUC for Layer 2: 0.5277\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.4928\n",
      "Test AUC for Layer 3: 0.4723\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4659\n",
      "Average Test AUC across all layers: 0.5072\n",
      "\n",
      "================================================================================\n",
      "Training model for Title and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.1970\n",
      "Test AUC for Layer 1: 0.5351\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.3333\n",
      "Test AUC for Layer 2: 0.5000\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 1500 features for Title inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4638\n",
      "Test AUC for Layer 3: 0.4383\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.3314\n",
      "Average Test AUC across all layers: 0.4911\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4394\n",
      "Test AUC for Layer 1: 0.4927\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4259\n",
      "Test AUC for Layer 2: 0.3676\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4928\n",
      "Test AUC for Layer 3: 0.4529\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4527\n",
      "Average Test AUC across all layers: 0.4378\n",
      "\n",
      "================================================================================\n",
      "Training model for Full text and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5758\n",
      "Test AUC for Layer 1: 0.5302\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.6019\n",
      "Test AUC for Layer 2: 0.5652\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Using 4000 features for Full text inputs\n",
      "Best parameters for Layer 3: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5507\n",
      "Test AUC for Layer 3: 0.5935\n",
      "Visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5761\n",
      "Average Test AUC across all layers: 0.5630\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (XOM)\n",
      "================================================================================\n",
      "\n",
      "Combination: Title + S_label\n",
      "Average Accuracy: 0.4659\n",
      "Average AUC: 0.5072\n",
      "  Layer 1 - Accuracy: 0.4697, AUC: 0.5215\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4352, AUC: 0.5277\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4928, AUC: 0.4723\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_S_label_layer_3.png\n",
      "\n",
      "Combination: Title + L_label\n",
      "Average Accuracy: 0.3314\n",
      "Average AUC: 0.4911\n",
      "  Layer 1 - Accuracy: 0.1970, AUC: 0.5351\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.3333, AUC: 0.5000\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4638, AUC: 0.4383\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Title/Title_L_label_layer_3.png\n",
      "\n",
      "Combination: Full text + S_label\n",
      "Average Accuracy: 0.4527\n",
      "Average AUC: 0.4378\n",
      "  Layer 1 - Accuracy: 0.4394, AUC: 0.4927\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 10, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.4259, AUC: 0.3676\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 0.1, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.4928, AUC: 0.4529\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_S_label_layer_3.png\n",
      "\n",
      "Combination: Full text + L_label\n",
      "Average Accuracy: 0.5761\n",
      "Average AUC: 0.5630\n",
      "  Layer 1 - Accuracy: 0.5758, AUC: 0.5302\n",
      "  Layer 1 - Best Parameters: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 1 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_1.png\n",
      "  Layer 2 - Accuracy: 0.6019, AUC: 0.5652\n",
      "  Layer 2 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "  Layer 2 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_2.png\n",
      "  Layer 3 - Accuracy: 0.5507, AUC: 0.5935\n",
      "  Layer 3 - Best Parameters: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "  Layer 3 - Visualization: TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/Full_text/Full_text_L_label_layer_3.png\n",
      "Summary comparison visualization saved as: TF-IDF_SVM_Plots/XOM/visualizations/summary_performance.png\n",
      "\n",
      "================================================================================\n",
      "VISUALIZATION PATHS SUMMARY\n",
      "================================================================================\n",
      "Summary visualization: TF-IDF_SVM_Plots/XOM/visualizations/summary_performance.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "        # Dictionary to track visualizations - new addition\n",
    "        self.visualizations = {\n",
    "            'learning_curves': {},  # Will store paths to learning curve plots\n",
    "            'feature_importance': {},  # Will store paths to feature importance plots\n",
    "            'summary': {}  # Will store paths to summary visualizations\n",
    "        }\n",
    "        \n",
    "        # Create visualization directory if it doesn't exist\n",
    "        os.makedirs('TF-IDF_SVM_Plots/XOM/visualizations', exist_ok=True)\n",
    "        os.makedirs('TF-IDF_SVM_Plots/XOM/visualizations/learning_curves', exist_ok=True)\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self, text_col):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model with max_features adjusted based on input type.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column being processed ('Title' or 'Full text')\n",
    "            \n",
    "        Returns:\n",
    "            A GridSearchCV model with the appropriate parameters\n",
    "        \"\"\"\n",
    "        # Set max_features based on the text column type - new implementation\n",
    "        if text_col == 'Title':\n",
    "            max_features = 1500  # Reduced feature set for titles\n",
    "            print(f\"Using {max_features} features for Title inputs\")\n",
    "        else:  # 'Full text'\n",
    "            max_features = 4000  # Larger feature set for full text\n",
    "            print(f\"Using {max_features} features for Full text inputs\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=max_features,  # Dynamic max_features based on input type\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}|{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        # Initialize visualization tracking for this combination\n",
    "        self.visualizations['learning_curves'][combination_key] = {}\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model - now passing text_col to determine max_features\n",
    "            model = self.create_model(text_col)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer\n",
    "            viz_path = self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "            \n",
    "            # Store visualization path in our dictionary - new implementation\n",
    "            self.visualizations['learning_curves'][combination_key][i+1] = viz_path\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        if self.results[combination_key]['accuracy']:\n",
    "            avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "            avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "            \n",
    "            print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "            print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "            \n",
    "            self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "            self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        else:\n",
    "            print(\"\\nNo valid results to calculate average metrics\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "            \n",
    "        Returns:\n",
    "            Path to the saved visualization\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        \n",
    "        # Create organized visualization directory structure\n",
    "        viz_dir = f\"TF-IDF_SVM_Plots/XOM/visualizations/learning_curves/{text_col.replace(' ', '_')}\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # Save figure with a more organized naming pattern\n",
    "        viz_path = f\"{viz_dir}/{text_col.replace(' ', '_')}_{label_col}_layer_{layer_num}.png\"\n",
    "        plt.savefig(viz_path)\n",
    "        print(f\"Visualization saved as: {viz_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        return viz_path\n",
    "    \n",
    "    def create_summary_visualization(self):\n",
    "        \"\"\"\n",
    "        Create a summary visualization comparing all model combinations.\n",
    "        \"\"\"\n",
    "        # Prepare data for visualization\n",
    "        combinations = []\n",
    "        accuracies = []\n",
    "        aucs = []\n",
    "        \n",
    "        for combo, results in self.results.items():\n",
    "            if 'avg_accuracy' in results and 'avg_auc' in results:\n",
    "                combinations.append(combo)\n",
    "                accuracies.append(results['avg_accuracy'])\n",
    "                aucs.append(results['avg_auc'])\n",
    "        \n",
    "        if not combinations:\n",
    "            print(\"No valid results to create summary visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Set up bar positions\n",
    "        x = np.arange(len(combinations))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot accuracy and AUC bars\n",
    "        plt.bar(x - width/2, accuracies, width, label='Average Accuracy', color='skyblue')\n",
    "        plt.bar(x + width/2, aucs, width, label='Average AUC', color='salmon')\n",
    "        \n",
    "        # Add labels and title\n",
    "        plt.xlabel('Model Combination')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Performance Comparison of Different Model Combinations')\n",
    "        plt.xticks(x, combinations, rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for i, v in enumerate(accuracies):\n",
    "            plt.text(i - width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(aucs):\n",
    "            plt.text(i + width/2, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.ylim(0, max(max(accuracies), max(aucs)) + 0.1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the visualization\n",
    "        summary_path = \"TF-IDF_SVM_Plots/XOM/visualizations/summary_performance.png\"\n",
    "        plt.savefig(summary_path)\n",
    "        print(f\"Summary comparison visualization saved as: {summary_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Store visualization path\n",
    "        self.visualizations['summary']['overall_performance'] = summary_path\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Title', 'S_label'),     # news headline + short-term prediction\n",
    "            ('Title', 'L_label'),     # news headline + long-term prediction\n",
    "            ('Full text', 'S_label'), # news body + short-term prediction\n",
    "            ('Full text', 'L_label')  # news body + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (XOM)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Create comprehensive summary table\n",
    "        for combination, results in self.results.items():\n",
    "            text_col, label_col = combination.split('|')\n",
    "            if 'avg_accuracy' in results:\n",
    "                print(f\"\\nCombination: {text_col} + {label_col}\")\n",
    "                print(f\"Average Accuracy: {results['avg_accuracy']:.4f}\")\n",
    "                print(f\"Average AUC: {results['avg_auc']:.4f}\")\n",
    "                \n",
    "                # Print layer-specific results\n",
    "                for i, accuracy in enumerate(results.get('accuracy', [])):\n",
    "                    auc = results.get('auc', [])[i]\n",
    "                    best_params = results.get('best_params', [])[i]\n",
    "                    print(f\"  Layer {i+1} - Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
    "                    print(f\"  Layer {i+1} - Best Parameters: {best_params}\")\n",
    "                    # Print path to visualization for this layer\n",
    "                    viz_path = self.visualizations['learning_curves'][combination].get(i+1, \"No visualization available\")\n",
    "                    print(f\"  Layer {i+1} - Visualization: {viz_path}\")\n",
    "        \n",
    "        # Create summary visualization\n",
    "        self.create_summary_visualization()\n",
    "        \n",
    "        # Print visualization paths summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VISUALIZATION PATHS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Summary visualization: {self.visualizations['summary'].get('overall_performance', 'Not created')}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_XOM_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 929 climate change news articles from Wall Street Journal spanning from 02/01/2019 to 07/05/2023\n",
      "Class distribution for short-term prediction: {0: 466, 1: 463}\n",
      "Class distribution for long-term prediction: {1: 507, 0: 422}\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and S_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 1: 0.4242\n",
      "Test AUC for Layer 1: 0.4937\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 2: 0.4352\n",
      "Test AUC for Layer 2: 0.3600\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 0.01, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l2'}\n",
      "Test Accuracy for Layer 3: 0.4783\n",
      "Test AUC for Layer 3: 0.4437\n",
      "Visualization saved as: visualization_Merged news_S_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.4459\n",
      "Average Test AUC across all layers: 0.4324\n",
      "\n",
      "================================================================================\n",
      "Training model for Merged news and L_label\n",
      "================================================================================\n",
      "\n",
      "Layer 1:\n",
      "Training period: 01/01/2019 - 31/05/2021\n",
      "Validation period: 01/06/2021 - 31/12/2021\n",
      "Testing period: 01/01/2022 - 31/05/2022\n",
      "Training data: 522 samples\n",
      "Validation data: 163 samples\n",
      "Test data: 66 samples\n",
      "Best parameters for Layer 1: {'classifier__C': 1, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 1: 0.5455\n",
      "Test AUC for Layer 1: 0.5127\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_1.png\n",
      "\n",
      "Layer 2:\n",
      "Training period: 01/01/2019 - 31/12/2021\n",
      "Validation period: 01/01/2022 - 31/05/2022\n",
      "Testing period: 01/06/2022 - 31/12/2022\n",
      "Training data: 685 samples\n",
      "Validation data: 66 samples\n",
      "Test data: 108 samples\n",
      "Best parameters for Layer 2: {'classifier__C': 100, 'classifier__class_weight': None, 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 2: 0.4907\n",
      "Test AUC for Layer 2: 0.4915\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_2.png\n",
      "\n",
      "Layer 3:\n",
      "Training period: 01/01/2019 - 31/05/2022\n",
      "Validation period: 01/06/2022 - 31/12/2022\n",
      "Testing period: 01/01/2023 - 31/05/2023\n",
      "Training data: 751 samples\n",
      "Validation data: 108 samples\n",
      "Test data: 69 samples\n",
      "Best parameters for Layer 3: {'classifier__C': 10, 'classifier__class_weight': 'balanced', 'classifier__loss': 'squared_hinge', 'classifier__penalty': 'l1'}\n",
      "Test Accuracy for Layer 3: 0.5652\n",
      "Test AUC for Layer 3: 0.5547\n",
      "Visualization saved as: visualization_Merged news_L_label_layer_3.png\n",
      "\n",
      "Average Test Accuracy across all layers: 0.5338\n",
      "Average Test AUC across all layers: 0.5196\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF RESULTS (XOM)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Define climate-finance specific stopwords to remove in addition to regular stopwords\n",
    "FINANCIAL_STOPWORDS = {\n",
    "    'said', 'inc', 'corp', 'company', 'companies', 'reuters', 'news', 'press', 'release',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', \n",
    "    'october', 'november', 'december', 'wall', 'street', 'journal'\n",
    "}\n",
    "\n",
    "# Define climate-finance terms to standardize\n",
    "CLIMATE_FINANCIAL_TERMS = {\n",
    "    'q1': 'first_quarter',\n",
    "    'q2': 'second_quarter',\n",
    "    'q3': 'third_quarter',\n",
    "    'q4': 'fourth_quarter',\n",
    "    'esg': 'environmental_social_governance',\n",
    "    'ghg': 'greenhouse_gas',\n",
    "    'co2': 'carbon_dioxide',\n",
    "    'carbon': 'carbon_emissions',\n",
    "    'renewable': 'renewable_energy',\n",
    "    'climate': 'climate_change',\n",
    "    'global warming': 'climate_change',\n",
    "    'green': 'green_energy',\n",
    "    'sustainable': 'sustainability',\n",
    "    'paris agreement': 'paris_climate_accord',\n",
    "    'emissions': 'carbon_emissions',\n",
    "    'environmental': 'environmental_impact',\n",
    "    'solar': 'renewable_energy_solar',\n",
    "    'wind': 'renewable_energy_wind',\n",
    "    'net zero': 'net_zero_emissions',\n",
    "    'clean energy': 'renewable_energy',\n",
    "    'fossil': 'fossil_fuel',\n",
    "    'coal': 'fossil_fuel_coal'\n",
    "}\n",
    "\n",
    "class ClimateNewsStockPredictor:\n",
    "    def __init__(self, csv_path):\n",
    "        \"\"\"\n",
    "        Initialize the stock predictor for climate change news analysis.\n",
    "        \n",
    "        Args:\n",
    "            csv_path: Path to the CSV file containing climate change news data from Wall Street Journal\n",
    "        \"\"\"\n",
    "        self.csv_path = csv_path\n",
    "        self.data = None\n",
    "        self.layers = []\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stopwords = set(stopwords.words('english')).union(FINANCIAL_STOPWORDS)\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load and preprocess the CSV data containing climate change news from Wall Street Journal.\"\"\"\n",
    "        self.data = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Convert date strings to datetime objects with mixed format detection\n",
    "        # Setting dayfirst=True helps correctly parse dates like DD/MM/YYYY\n",
    "        try:\n",
    "            self.data['Publication date'] = pd.to_datetime(self.data['Publication date'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Short'] = pd.to_datetime(self.data['Predicting date Short'], format='mixed', dayfirst=True)\n",
    "            self.data['Predicting date Long'] = pd.to_datetime(self.data['Predicting date Long'], format='mixed', dayfirst=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # If 'mixed' isn't supported in your pandas version, try a manual approach\n",
    "            print(\"Mixed format not supported in your pandas version. Trying manual conversion...\")\n",
    "            \n",
    "            # Helper function to handle different date formats\n",
    "            def parse_date_column(column):\n",
    "                result = []\n",
    "                for date_str in column:\n",
    "                    try:\n",
    "                        # Try to parse as YYYY-MM-DD\n",
    "                        date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            # Try to parse as DD/MM/YYYY\n",
    "                            date = pd.to_datetime(date_str, format='%d/%m/%Y')\n",
    "                        except ValueError:\n",
    "                            # As a last resort, let pandas guess\n",
    "                            date = pd.to_datetime(date_str, dayfirst=True)\n",
    "                    result.append(date)\n",
    "                return pd.Series(result)\n",
    "            \n",
    "            self.data['Publication date'] = parse_date_column(self.data['Publication date'])\n",
    "            self.data['Predicting date Short'] = parse_date_column(self.data['Predicting date Short'])\n",
    "            self.data['Predicting date Long'] = parse_date_column(self.data['Predicting date Long'])\n",
    "        \n",
    "        # Sort by publication date\n",
    "        self.data = self.data.sort_values('Publication date')\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} climate change news articles from Wall Street Journal spanning from \"\n",
    "              f\"{self.data['Publication date'].min().strftime('%d/%m/%Y')} \"\n",
    "              f\"to {self.data['Publication date'].max().strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Class distribution for short-term prediction: {self.data['S_label'].value_counts().to_dict()}\")\n",
    "        print(f\"Class distribution for long-term prediction: {self.data['L_label'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess climate change news text by applying various NLP techniques.\n",
    "        \n",
    "        Args:\n",
    "            text: The text to preprocess\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Standardize climate-finance terms\n",
    "        for term, replacement in CLIMATE_FINANCIAL_TERMS.items():\n",
    "            text = re.sub(r'\\b' + term + r'\\b', replacement, text)\n",
    "        \n",
    "        # Standardize numerical representations with units\n",
    "        text = re.sub(r'\\$(\\d+)([kmbt])', lambda m: m.group(1) + '_' + \n",
    "                      {'k': 'thousand', 'm': 'million', 'b': 'billion', 't': 'trillion'}[m.group(2).lower()], text)\n",
    "        \n",
    "        # Remove punctuation except $ and %\n",
    "        text = re.sub(r'[^\\w\\s$%]', ' ', text)\n",
    "        \n",
    "        # Remove non-alphanumeric characters but preserve meaningful financial symbols\n",
    "        text = re.sub(r'[^\\w\\s$%.-]', ' ', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens if token not in self.stopwords]\n",
    "        \n",
    "        # Join tokens back into a string\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def define_time_windows(self):\n",
    "        \"\"\"Define the time windows for the sliding window approach.\"\"\"\n",
    "        # First layer: train (2019-2021), validation (2021-2021), test (2022-2022)\n",
    "        layer1 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-05-31'),\n",
    "            'val_start': pd.Timestamp('2021-06-01'),\n",
    "            'val_end': pd.Timestamp('2021-12-31'),\n",
    "            'test_start': pd.Timestamp('2022-01-01'),\n",
    "            'test_end': pd.Timestamp('2022-05-31')\n",
    "        }\n",
    "        \n",
    "        # Second layer: train (2019-2021), validation (2022-2022), test (2022-2022)\n",
    "        layer2 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2021-12-31'),\n",
    "            'val_start': pd.Timestamp('2022-01-01'),\n",
    "            'val_end': pd.Timestamp('2022-05-31'),\n",
    "            'test_start': pd.Timestamp('2022-06-01'),\n",
    "            'test_end': pd.Timestamp('2022-12-31')\n",
    "        }\n",
    "        \n",
    "        # Third layer: train (2019-2022), validation (2022-2022), test (2023-2023)\n",
    "        layer3 = {\n",
    "            'train_start': pd.Timestamp('2019-01-01'),\n",
    "            'train_end': pd.Timestamp('2022-05-31'),\n",
    "            'val_start': pd.Timestamp('2022-06-01'),\n",
    "            'val_end': pd.Timestamp('2022-12-31'),\n",
    "            'test_start': pd.Timestamp('2023-01-01'),\n",
    "            'test_end': pd.Timestamp('2023-05-31')\n",
    "        }\n",
    "        \n",
    "        self.layers = [layer1, layer2, layer3]\n",
    "        return self\n",
    "    \n",
    "    def split_data(self, layer, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Split the data into training, validation, and test sets based on the defined time windows.\n",
    "        \n",
    "        Args:\n",
    "            layer: The time window layer\n",
    "            text_col: The column containing the text data ('Title' or 'Full text')\n",
    "            label_col: The column containing the labels ('S_label' or 'L_label')\n",
    "            \n",
    "        Returns:\n",
    "            train_data, val_data, test_data\n",
    "        \"\"\"\n",
    "        train_mask = (self.data['Publication date'] >= layer['train_start']) & (self.data['Publication date'] <= layer['train_end'])\n",
    "        val_mask = (self.data['Publication date'] > layer['val_start']) & (self.data['Publication date'] <= layer['val_end'])\n",
    "        test_mask = (self.data['Publication date'] > layer['test_start']) & (self.data['Publication date'] <= layer['test_end'])\n",
    "        \n",
    "        train_data = self.data[train_mask]\n",
    "        val_data = self.data[val_mask]\n",
    "        test_data = self.data[test_mask]\n",
    "        \n",
    "        print(f\"Training data: {len(train_data)} samples\")\n",
    "        print(f\"Validation data: {len(val_data)} samples\")\n",
    "        print(f\"Test data: {len(test_data)} samples\")\n",
    "        \n",
    "        # Preprocess text\n",
    "        X_train = train_data[text_col].apply(self.preprocess_text)\n",
    "        X_val = val_data[text_col].apply(self.preprocess_text)\n",
    "        X_test = test_data[text_col].apply(self.preprocess_text)\n",
    "        \n",
    "        y_train = train_data[label_col]\n",
    "        y_val = val_data[label_col]\n",
    "        y_test = test_data[label_col]\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data\n",
    "    \n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF + SVM pipeline model.\n",
    "\n",
    "        \"\"\"\n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=5000,  # Limit to top 5000 features\n",
    "                min_df=5,           # Remove terms that appear in fewer than 5 documents\n",
    "                max_df=0.85,        # Remove terms that appear in more than 85% of documents\n",
    "                ngram_range=(1, 3), # Include unigrams, bigrams, and trigrams\n",
    "                sublinear_tf=True   # Apply sublinear tf scaling (1 + log(tf))\n",
    "            )),\n",
    "            ('classifier', LinearSVC(\n",
    "                random_state=42,\n",
    "                max_iter=2000,\n",
    "                dual=False          # Better performance when n_samples > n_features\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # Define parameters for grid search\n",
    "        param_grid = {\n",
    "            'classifier__C': [0.01, 0.1, 1, 10, 100],          # Regularization parameter\n",
    "            'classifier__loss': ['hinge', 'squared_hinge'],    # Loss function\n",
    "            'classifier__penalty': ['l1', 'l2'],               # Penalty norm\n",
    "            'classifier__class_weight': [None, 'balanced']     # Weight classes inversely proportional to frequencies\n",
    "        }\n",
    "        \n",
    "        # Create grid search model - this is done for each layer independently\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid,\n",
    "            cv=3,                # 3-fold cross-validation\n",
    "            scoring='roc_auc',   # Optimize for ROC AUC\n",
    "            verbose=0,\n",
    "            n_jobs=-1            # Use all available cores\n",
    "        )\n",
    "        \n",
    "        return grid_search\n",
    "    \n",
    "    def train_and_evaluate(self, text_col, label_col):\n",
    "        \"\"\"\n",
    "        Train and evaluate the model for a specific text column and label column.\n",
    "        \n",
    "        Args:\n",
    "            text_col: The text column to use ('Title' or 'Full text')\n",
    "            label_col: The label column to use ('S_label' or 'L_label')\n",
    "        \"\"\"\n",
    "        # Store results\n",
    "        combination_key = f\"{text_col}_{label_col}\"\n",
    "        self.results[combination_key] = {\n",
    "            'accuracy': [],\n",
    "            'auc': [],\n",
    "            'best_params': [],\n",
    "            'layer_results': []\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training model for {text_col} and {label_col}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"\\nLayer {i+1}:\")\n",
    "            print(f\"Training period: {layer['train_start'].strftime('%d/%m/%Y')} - {layer['train_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Validation period: {layer['val_start'].strftime('%d/%m/%Y')} - {layer['val_end'].strftime('%d/%m/%Y')}\")\n",
    "            print(f\"Testing period: {layer['test_start'].strftime('%d/%m/%Y')} - {layer['test_end'].strftime('%d/%m/%Y')}\")\n",
    "            \n",
    "            # Split data\n",
    "            (X_train, y_train), (X_val, y_val), (X_test, y_test), train_data, val_data, test_data = self.split_data(layer, text_col, label_col)\n",
    "            \n",
    "            # Check if there are enough samples and classes\n",
    "            if len(X_train) < 10 or len(np.unique(y_train)) < 2 or len(np.unique(y_val)) < 2 or len(np.unique(y_test)) < 2:\n",
    "                print(f\"Skipping layer {i+1} due to insufficient data or class imbalance\")\n",
    "                continue\n",
    "            \n",
    "            # Create and train model\n",
    "            # Grid search is performed for each layer independently\n",
    "            model = self.create_model()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model and parameters for this specific layer\n",
    "            best_model = model.best_estimator_\n",
    "            best_params = model.best_params_\n",
    "            \n",
    "            # Save best parameters for this layer\n",
    "            self.results[combination_key]['best_params'].append(best_params)\n",
    "            print(f\"Best parameters for Layer {i+1}: {best_params}\")\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_pred_proba = best_model.decision_function(X_test)\n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            auc = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            self.results[combination_key]['accuracy'].append(accuracy)\n",
    "            self.results[combination_key]['auc'].append(auc)\n",
    "            \n",
    "            print(f\"Test Accuracy for Layer {i+1}: {accuracy:.4f}\")\n",
    "            print(f\"Test AUC for Layer {i+1}: {auc:.4f}\")\n",
    "            \n",
    "            # Store layer results for visualization\n",
    "            layer_result = {\n",
    "                'layer': i+1,\n",
    "                'model': best_model,\n",
    "                'train_data': train_data,\n",
    "                'val_data': val_data,\n",
    "                'test_data': test_data,\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'accuracy': accuracy,\n",
    "                'auc': auc,\n",
    "                'best_params': best_params  # Store best parameters for this layer\n",
    "            }\n",
    "            \n",
    "            self.results[combination_key]['layer_results'].append(layer_result)\n",
    "            \n",
    "            # Visualize results for this layer - only top features and learning curve\n",
    "            self.visualize_layer_results(layer_result, text_col, label_col, i+1)\n",
    "        \n",
    "        # Calculate average metrics\n",
    "        avg_accuracy = np.mean(self.results[combination_key]['accuracy'])\n",
    "        avg_auc = np.mean(self.results[combination_key]['auc'])\n",
    "        \n",
    "        print(f\"\\nAverage Test Accuracy across all layers: {avg_accuracy:.4f}\")\n",
    "        print(f\"Average Test AUC across all layers: {avg_auc:.4f}\")\n",
    "        \n",
    "        self.results[combination_key]['avg_accuracy'] = avg_accuracy\n",
    "        self.results[combination_key]['avg_auc'] = avg_auc\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def visualize_layer_results(self, layer_result, text_col, label_col, layer_num):\n",
    "        \"\"\"\n",
    "        Visualize learning curve for a specific layer.\n",
    "        \n",
    "        Args:\n",
    "            layer_result: The results for the layer\n",
    "            text_col: The text column used\n",
    "            label_col: The label column used\n",
    "            layer_num: The layer number\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.suptitle(f\"Model Evaluation: {text_col} + {label_col} (Layer {layer_num})\", fontsize=16)\n",
    "        \n",
    "        # Learning Curve (using accuracy on different dataset sizes)\n",
    "        \n",
    "        # Get train data\n",
    "        X_train = layer_result['X_train']\n",
    "        y_train = layer_result['y_train']\n",
    "        \n",
    "        # Create different training set sizes\n",
    "        train_sizes = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for size in train_sizes:\n",
    "            # Get subset of training data\n",
    "            n_samples = int(len(X_train) * size)\n",
    "            X_train_subset = X_train.iloc[:n_samples]\n",
    "            y_train_subset = y_train.iloc[:n_samples]\n",
    "            \n",
    "            # Train a new model\n",
    "            model_clone = clone(layer_result['model'])\n",
    "            model_clone.fit(X_train_subset, y_train_subset)\n",
    "            \n",
    "            # Evaluate on training and validation sets\n",
    "            y_train_pred = model_clone.predict(X_train_subset)\n",
    "            y_val_pred = model_clone.predict(layer_result['X_val'])\n",
    "            \n",
    "            train_acc.append(accuracy_score(y_train_subset, y_train_pred))\n",
    "            val_acc.append(accuracy_score(layer_result['y_val'], y_val_pred))\n",
    "        \n",
    "        plt.plot(train_sizes, train_acc, 'o-', label='Training Accuracy')\n",
    "        plt.plot(train_sizes, val_acc, 'o-', label='Validation Accuracy')\n",
    "        plt.title('Learning Curve (Overfitting Detection)')\n",
    "        plt.xlabel('Training Set Size (%)')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"F:/Python/my jupyter notebook/Merged_TF-IDF_SVM_Plots/XOM/visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        print(f\"Visualization saved as: visualization_{text_col}_{label_col}_layer_{layer_num}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def run_all_combinations(self):\n",
    "        \"\"\"Run the analysis for all combinations of text and label columns.\"\"\"\n",
    "        # Define all combinations\n",
    "        combinations = [\n",
    "            ('Merged news', 'S_label'),     # Merged news + short-term prediction\n",
    "            ('Merged news', 'L_label'),     # Merged news + long-term prediction\n",
    "        ]\n",
    "        \n",
    "        # Run analysis for each combination\n",
    "        for text_col, label_col in combinations:\n",
    "            self.train_and_evaluate(text_col, label_col)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUMMARY OF RESULTS (XOM)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = ClimateNewsStockPredictor('E:/User/Documents/Documents (UK)/Cardiff (PhD)/First Year/climate change/US_news/SP500_semantic/us_news_semantics_XOM_completed.csv')\n",
    "    predictor.load_data().define_time_windows().run_all_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python3",
   "language": "python",
   "name": "my_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
